{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50c79fff-da30-4fce-b40e-a02aba357117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8e8160-2b97-4d10-b0cd-9c82f4e2e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [os.path.join('./lectures', text) for text in os.listdir('./lectures')]\n",
    "g = open('essay.txt', 'w')\n",
    "for text in texts:\n",
    "    with open(text, \"r\",  encoding=\"utf-8\") as f:\n",
    "        t = f.read()\n",
    "        g.write(t)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ca6ad9-c270-4aee-b461-96b942bc6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('essay.txt', \"r\") as g:\n",
    "    text = g.read()\n",
    "    chunk_size = 2048\n",
    "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac870535-0ad6-4088-9526-26bffe2b87b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a19d469a-2f13-4c77-b41b-15c8fcf54f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(api_key='',model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "faiss_index = FAISS.from_texts(chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d73aae-f482-4a38-be1e-82db8fbe091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = faiss_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "434fa1df-59af-4e2c-a1c9-42395563d575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3c77d10c1e4cdbb2b827403ece1722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   6%|5         | 147M/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e6b8632ab94210972a7921ab0743c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4585dde6505428cbf719743766df7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818519fdbea5486bbde935e2b725cfc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"meta-llama/llama-3.2-1B\",\n",
    "    token=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30257a58-50dc-4a06-9f0a-6d006b009ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asche\\AppData\\Local\\Temp\\ipykernel_19208\\2527154434.py:3: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=hf_pipeline)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18dc8ac7-eaad-4c82-b30f-92e373a5de8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import langchain.chains\n",
    "import langchain.prompts\n",
    "\n",
    "prompt = \"\"\"\n",
    "Пожалуйста, посмотри на текст ниже и ответь на вопрос, используя информацию из этого текста. Выведи только\n",
    "краткий ответ, не надо пояснительного текста.\n",
    "Текст:\n",
    "-----\n",
    "{context}\n",
    "-----\n",
    "Вопрос:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = langchain.prompts.PromptTemplate(\n",
    "    template=prompt, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain = langchain.chains.RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cceec88-a2b9-4407-b8cc-76a87509b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "570156aa-3104-4cb0-a6f9-c4c0611d4e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Условной вероятностью события $A$ при условии наступления события $B$ называется величина $ P(A | B) = \f",
      "rac{P(A \\cap B)}{P(B)} $\n"
     ]
    }
   ],
   "source": [
    "query = \"Что такое условная вероятность?\"\n",
    "result = chain.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831c3d4-93b4-4db5-880b-9925fd3f3bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
