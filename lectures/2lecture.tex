\subsection{Математические модели случайного эксперимента}

\begin{itemize}
	\item Если $|\Omega| < \infty$, то такие модели называются \textit{дискретными}. Множество событий полагают равным $F = 2^\Omega$. Единственный вопрос, который остаётся открытым - Как задавать вероятность?
	\begin{enumerate}
		\item Классическая модель. В ней все вероятности элементарных событий равны:
		\[
			\Omega = \{w_i\}_{i = 1}^N; \quad \forall i \in \{1, \ldots, n\}\ \ P(\{w_i\}) = const = C
		\]
		Отсюда выводим вероятность одного исхода:
		\[
			1 = P(\Omega) = P\left(\bscup_{i = 1}^N \{w_i\}\right) = \sum_{i = 1}^N P(\{w_i\}) = C \cdot N \Longrightarrow C = \frac{1}{N} = \frac{1}{|\Omega|}
		\]
		Если у нас есть $\mathcal{A} \in F$, то вероятность такого события можно посчитать из определения:
		\[
			P(\mathcal{A}) = \sum_{w \in \mathcal{A}} P(\{w\}) = \sum_{w \in A} \frac{1}{|\Omega|} = \frac{|\mathcal{A}|}{|\Omega|}
		\]
		
		\item Неклассическая модель. В ней, очевидно, вероятности элементарных событий могут быть не равны. Обычно они задаются поточечно в силу конечности $\Omega$. Если есть событие $\mathcal{A} \in F$, то вероятность считают по одной формуле:
		\[
			P(\mathcal{A}) = \sum_{w \in \mathcal{A}} P({w})
		\]
		
		\begin{example}
			$n \ge 3$ незнакомых людей садятся за круглый стол. Найти вероятность того, что 2 конкретных человека окажутся рядом.
			
			Рассмотрим математические модели, которыми бы можно было описать эту задачу:
			\begin{enumerate}
				\item $w = (i_1, \ldots, i_n)$, где $i_j$ - это номер места, куда сядет $j$-й человек. Тогда $|\Omega| = n!$, а вероятность нашего события будет
				\[
					P(A) = \frac{|A|}{|\Omega|} = \frac{n \cdot 2 \cdot (n - 2)!}{n!} = \frac{2}{n - 1}
				\]
				
				\item $w = (x, y)$ - позиции, которые займут интересующие нас люди (без разбора, кто сядет первый). Тогда всего исходов $|\Omega| = C_n^2$, а вероятность нужного события будет
				\[
					P(A) = \frac{|A|}{|\Omega|} = \frac{n}{C_n^2} = \frac{n}{\frac{n(n - 1)}{2}} = \frac{2}{n - 1}
				\]
			\end{enumerate}
		\end{example}
	
		\begin{note}
			Это замечательно, когда задача сформулирована полно и разные модели дают одинаковую вероятность. Однако, бывает и иначе, но об этом будет сильно позже...
		\end{note}
	
		\begin{example}
			Есть $N$ изделий, среди которых $M$ бракованных. Найти вероятность того, что среди $n \le N$ выбранных изделий будет ровно $0 \le k \le n$ бракованных.
		
			\begin{enumerate}
				\item Положим $w = (i_1, \ldots, i_n)$, где $i_j$ --- номер изделия при $j$-м вытаскивании. Тогда $|\Omega| = N^n$, а вероятность интересующего нас события будет
				\[
					P(A) = \frac{C_n^k \cdot M^k \cdot (N - M)^{n - k}}{N^n} = C_n^k \cdot p^k \cdot (1 - p)^{n - k}
				\]
				
				\item (Пример схемы испытаний Бернулли) Теперь $w = (l_1, \ldots, l_n)$, где $l_i \in \{0, 1\}$ --- бракован элемент или нет. Тогда $|\Omega| = 2^n$, $F = 2^\Omega$, а вероятность выбора бракованного элемента положим за $p = M / N$. Тогда, мы можем поточечно задать вероятность одного исхода, опираясь на предыдущую модель:
				\[
					P(\{w\}) = p^{\text{\#единиц}} \cdot (1 - p)^{\text{\#нулей}}
				\]
				где количество единиц можно выразить как $\sum_{i = 1}^n l_i$. Но очевидно ли, что $P(\Omega) = 1$? Вообще говоря, нет. Нужно это проверить:
				\[
					P(\Omega) = \sum_{w \in \Omega} p^{\sum_{i = 1}^n l_i} (1 - p)^{n - \sum_{i = 1}^n l_i} = \sum_{k = 0}^n C_n^k p^k (1 - p)^{n - k} = (p + (1 - p))^n = 1
				\]
				Вероятность $P(A)$ будет той же.
			\end{enumerate}
		\end{example}
	
		\begin{example}
			Тихон играет с другом в монетку. С вероятностью $p \in (0; 1)$ он выигрывает (выпадает сторона, которую он выбрал). Какова вероятность того, что он выиграет первый раз на $n$-м шаге?
			
			Казалось бы, ничего сложного нет:
			\[
				P(\{w\}) = P(\text{Тихон выиграет на $n$-м шаге}) = p(1 - p)^{n - 1}
			\]
			Но есть 2 больших проблемы: во-первых, $\Omega = \N$, а $F = 2^\Omega \cong \R$, то есть мы не в дискретной модели. Во-вторых, нам снова нужно проверить корректность модели. Все свойства очевидны, за исключением $P(\Omega)$:
			\[
				P(\Omega) = \sum_{w \in \Omega} P(\{w\}) = \sum_{k = 1}^\infty p(1 - p)^{k - 1} = p \cdot \frac{1}{1 - (1 - p)} = 1
			\]
			Быть может, в счётных моделях всё хорошо? К сожалению, уже здесь всё может сломаться, и следующий пример об этом.
		\end{example}
	
		\begin{example} (Некорректная неклассическая модель)
			Рассмотрим такую модель: $\Omega = \Q \cap [0; 1]$, а $F = 2^\Omega = \{\Q \cap [a; b] \such 0 \le a \le b \le 1\}$. Иначе говоря, мы рассматриваем вероятности множеств рациональных точек на $[0; 1]$ быть выбранными. Интуитивно хочется взять такую вероятность:
			\[
				P(\Q \cap [a; b]) = b - a \Lora \forall r_n \in \Omega\ \ P(\{r_n\}) = 0
			\]
			Из определения $\Omega$ следует, что $P(\Omega) = 1$. Однако, в силу счётности числа рациональных точек, мы можем переписать $\Omega$ в следующем виде:
			\[
				\Omega = \bscup_{k = 1}^\infty \{r_k\} \Lora P(\Omega) = \sum_{k = 1}^\infty P(\{r_k\}) = 0
			\]
			Поэтому требование счётной аддитивности меры существенно. А если ещё внимательно посмотреть на $F$, то можно заметить, что это не $\sigma$-алгебра (объединение не обязательно единый отрезок).
		\end{example}
	\end{enumerate}

	\item Недискретная модель (Геометрическая вероятность). В ней обычно $\Omega \subset \R^n$, $\mu(\Omega) < \infty$, а за вероятность события $A$ берут
	\[
		P(A) = \frac{\mu(A)}{\mu(\Omega)}
	\]
	Остаётся вопрос: <<Что делать с $F$?>> Совершенно понятно, что мы не имеем права брать $F = 2^\Omega$ из-за требований модели. Вообще говоря, это зависит от задачи, но мы можем временно опустить этот вопрос. Вероятность важна и имеет смысл только для наших конкретных событий. Это ровно то, почему $P$ определена на элементах из $F$.
\end{itemize}

\section{Формулы теории вероятности}

\subsection{Условная вероятность}

\textcolor{red}{Сюда надо картинку следующего толка: кружочек $\Omega$, в нём 2 пересекающихся события $A$ и $B$. Надо выделить пересечение.}

\begin{note}
	Довольно часто мы рассматриваем не просто события, но и вероятность одного при условии, что произойдёт другое. Для этой мысли нам нужно расширить понятие вероятности.
\end{note}

\begin{definition}
	\textit{Условной вероятностью} события $A$ при условии наступления события $B$ ($P(B) \neq 0$) называется величина
	\[
		P(A | B) = \frac{P(A \cap B)}{P(B)}
	\]
\end{definition}

\begin{note}
	Интуиция тут такая: мы рассмотрели вероятность события $A \cap B$ как будто $\Omega = B$. Именно по этой причине нужно делить на $P(B)$.
\end{note}

\begin{example}
	Вернёмся к игре в монетку с Тихоном. Какова вероятность Тихона выиграть суммарно $k$ раз за $n$ партий, если вероятность победы всё ещё $p \in (0; 1)$ и он \textit{выиграл} первый бросок?
	\begin{itemize}
		\item Быстрый ответ будет $C_{n - 1}^{k - 1} p^{k - 1} (1 - p)^{n - k}$ - просто посчитали число подходящих бинарных строк и умножили на вероятность $k - 1$ победы
		
		\item Пусть $A$ означает выиграть ровно $k$ раз за $n$ бросков, а $B$ - выиграть первую партию. Тогда верно следующее:
		\[
			\left.\begin{aligned}
				&{P(A \cap B) = C_{n - 1}^{k - 1} p^k (1 - p)^{n - k}} 
				\\
				&{P(B) = p}
			\end{aligned}\right\}
			\Ra P(A|B) = C_{n - 1}^{k - 1} p^{k - 1} (1 - p)^{n - k}
		\]
	\end{itemize}
\end{example}

\subsection{Формула полной вероятности}

\begin{definition}
	\textit{Разбиением $\Omega$ над $F$} называется последовательность множеств $\{B_k\}_{k = 1}^{n(\infty)} \subseteq F$ такая, что
	\begin{enumerate}
		\item $\forall i \neq j \Ra B_i \cap B_j = \emptyset$
		
		\item $\bscup_{i = 1}^{n (\infty)} B_i = \Omega$
	\end{enumerate}
\end{definition}

\begin{note}
	$n(\infty)$ означает либо конечную, либо бесконечную последовательность.
\end{note}

\begin{theorem}
	Если $\{B_k\}_{k = 1}^{n(\infty)}$ - разбиение $\Omega$ и верно, что $\forall k\ P(B_k) > 0$, то
	\[
		\forall A \in F \quad P(A) = \sum_{k = 1}^{n(\infty)} P(A|B_k) \cdot P(B_k)
	\]
\end{theorem}

\begin{proof}
	Благодаря тому, что у нас есть счётная аддитивность, следующая цепочка равенств будет верна:
	\[
		P(A) = P(A \cap \Omega) = P\ps{A \cap \bscup_{k = 1}^{n(\infty)} B_k} = \sum_{k = 1}^{n(\infty)} P(A \cap B_k) = \sum_{k = 1}^{n(\infty)} P(A|B_k) \cdot P(B_k)
	\]
\end{proof}

\begin{note}
	А что же всё-таки будет, если $P(B) = 0$? Хочется сказать, что $P(A|B) = 0$, но всё равно непонятно, из каких соображений.
\end{note}

\begin{example}
	<<Какова вероятность того, что зарплата среднего работника будет больше 1000 условных единиц при температуре 12.8 градусов Цельсия>> --- вполне справедливый вопрос, на который мы сейчас не можем дать ответа в силу бедности математического аппарата. Можно рассмотреть температуру как непрерывную функцию и получить $P(t = 12.8) = 0$, но это не соответствует реальности. Что-то более вменяемое может рассказать область математической статистики, но это выходит за рамки курса ОВиТМа.
\end{example}