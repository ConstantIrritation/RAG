\begin{example}
	И всё же рассмотрим применение формулы полной вероятности. Пусть есть 3 студента, которых и только их вызывает семинарист к доске (назовём их, например, Умный, Весёлый и Староста и введём соответствующую нумерацию). Тогда $B_k$ - это событие, когда семинарист вызывает $k \in \range{3}$ студента. $A$ - это событие, что студент даёт верный ответ.
	\begin{itemize}
		\item $P(B_1) = 1/6$, чтобы на семинарах группа хоть как-то продвигалась; $P(A | B_1) = 1$
		
		\item $P(B_2) = 1/2$, потому что иногда хочется передохнуть и не дать семинару стать <<душным>>; $P(A | B_2) = 1 / 10$
		
		\item $P(B_3) = 1/3$, просто из соображений суммы вероятностей; $P(A | B_3) = 1 / 3$
	\end{itemize}
	Тогда, посчитаем $P(A)$:
	\[
		P(A) = 1 / 6 + 1 / 20 + 1 / 9 = 59 / 180 \approx 1 / 3
	\]
\end{example}

\subsection{Формула Байеса}

\begin{note}
	a priori --- знания, полученные до опыта и независимо от него, а a posteriori --- знания, полученные с опытом.
\end{note}

\begin{example}
	Вернёмся к последнему примеру. Предположим, что прошёл семинар, на котором решили пару задач, семинарист поставил плюсики на лист, но не записал, кто именно решил ту или иную задачу. Отсюда рождается желание узнать $P(B_k | A)$ --- вероятность того, что ответ был дан $k$-м студентом. Такую вероятность можно назвать \textit{постериорной}, потому что мы знаем желаемый результат эксперимента, но не знаем, как его достигли.
\end{example}

\begin{theorem} (Формула Байеса)
	Утверждается, что постериорную вероятность $P(B_k | A)$ можно найти по следующей формуле:
	\[
		P(B_k | A) = \frac{P(A | B_k) \cdot P(B_k)}{\sum_{k = 1}^{n(\infty)} P(A | B_k) \cdot P(B_k)}
	\]
\end{theorem}

\begin{proof}
	Ну, тут даже комментировать не надо
	\[
		P(B_k | A) = \frac{P(A \cap B_k)}{P(A)} = \frac{P(A | B_k) \cdot P(B_k)}{\sum_{k = 1}^{n(\infty)} P(A | B_k) \cdot P(B_k)}
	\]
\end{proof}

\begin{example}
	В нашем примере, если мы посмотрим на $B_1$, то получим такую вероятность:
	\[
		P(B_1 | A) = \frac{1 / 6 \cdot 1}{59 / 180} = \frac{30}{59} \approx 1 / 2
	\]
	Это сходится с интуицией: если ответ был дан, то его с большой вероятностью должен был дать Умный студент.
\end{example}

\subsection{Формула умножения вероятностей}

\begin{example}
	Есть урна с 7 белыми и 9 красными шарами. Мы вытаскиваем без возвращения 3 шара. Какова вероятность того, что мы последовательно вытащим сначала белый, потом красный, а потом белый.
	
	Если прямо сейчас освободить разум, то можно дать следующий ответ:
	\[
		P(A) = \frac{7}{16} \cdot \frac{5}{15} \cdot \frac{6}{14}
	\]
	Но как это обосновать? Сказать, что вероятности независимы? Это не так, ведь для второго и третьего множителя мы учитываем, что шаров становится меньше.
\end{example}

\begin{note}
	Если между множествами в формуле не стоит никакой записи, то принято воспринимать это как их пересечение:
	\[
		\forall A, B \quad AB := A \cap B
	\]
\end{note}

\begin{theorem} (Формула умножения вероятностей)
	Если $A_1, \ldots, A_n \in F$, $P(A_i) > 0$, то
	\[
		P(A_1 \ldots A_n) = P(A_1) \cdot P(A_2 | A_1) \cdot P(A_3 | A_1A_2) \cdot \ldots \cdot P(A_n | A_1 \ldots A_{n - 1})
	\]
\end{theorem}

\begin{proof}
	Просто распишем нашу вероятность через формулу условной вероятности:
	\begin{align*}
		&{P(A_1 \ldots A_n) = P(A_n | A_1 \ldots A_{n - 1}) \cdot P(A_1 \ldots A_{n - 1})}
		\\
		&{\vdots}
		\\
		&{P(A_1 A_2) = P(A_2 | A_1) \cdot P(A_1)}
	\end{align*}
\end{proof}

\subsection{Независимость событий}

\subsubsection*{Независимость 2 событий}

\begin{note}
	Интуитивно понятно, чего мы хотим: вероятность одного события никак не зависит от того, было ли другое событие:
	\[
		P(A | B) = P(A)
	\]
	но, естественно, тут у нас есть поправка на $P(B) \neq 0$. Как этого избежать? Записать условную вероятность по определению и домножить на $P(B)$.
\end{note}

\begin{definition}
	События $A, B$ называются \textit{независимыми}, если выполнено равенство:
	\[
		P(A \cap B) = P(A) \cdot P(B)
	\]
	Обозначается как $A \indep B$.
\end{definition}

\begin{note}
	Независимость событий играет центральную роль в теории вероятности как отличной от математического анализа области. Действительно, если воспринимать меру как <<продолжение>> площади, то что выходит: какие-то объекты таковы, что их <<площадь>> их пересечения находится через произведение <<площадей>>? Такого в курсе анализа не встретишь.
\end{note}

\begin{example}
	При построении схемы испытаний Бернулли, мы уже интуитивно пользовались независимостью каждого эксперимента. А теперь на $\Omega = \{0, 1\}^n$ рассмотрим 2 таких события:
	\begin{align*}
		&{A = \{w \in \Omega \such w_1 = 1\}}
		\\
		&{B = \{w \in \Omega \such w_n = 1\}}
	\end{align*}
	Казалось бы, $A$ и $B$ должны быть независимы. Проверим это:
	\begin{align*}
		&{P(A) = p}
		\\
		&{P(B) = p}
		\\
		&{P(A \cap B) = \sum_{w \over w_1 = w_n = 1} p^{\sum_{i = 1}^n w_i} (1 - p)^{n - \sum_{i = 1}^n w_i}} = p^2 \sum_{w \over w_1 = w_n = 1} p^{\sum_{i = 2}^{n - 1} w_i} (1 - p)^{(n - 2) - \sum_{i = 2}^{n - 1} w_i} = p^2
	\end{align*}
\end{example}

\subsubsection*{Независимость $n$ событий}

\begin{definition}
	События $A_1, \ldots, A_n$ называются \textit{независимыми попарно}, если $\forall i \neq j\ A_i \indep A_j$
\end{definition}

\begin{definition}
	События $A_1, \ldots, A_n$ называются \textit{независимыми в совокупности}, если выполнено следующее условие:
	\[
		\forall k \in \range{n}\ \forall 1 \le i_1 < \ldots < i_k \le n \quad P(A_{i_1} \ldots A_{i_k}) = P(A_{i_1}) \cdot \ldots \cdot P(A_{i_k})
	\]
\end{definition}

\begin{note}
	Из независимости в совокупности следует независимость попарно (просто делаем $k = 2$), а вот в обратную сторону неверно.
\end{note}

\begin{example} (Бернштейна)
	Возьмём в пространстве правильный тетраэдр. Три его вершины покрасим в серый, чёрный и оранжевый цвета соответственно, а последнюю в их смесь (будем считать, что это соответствует трём цветами одновременно). Будем равновероятно выбирать любую вершину. Тогда:
	\begin{itemize}
		\item $A$ - событие, что выбранная вершина будет серой
		
		\item $B$ - событие, что выбранная вершина будет чёрной
		
		\item $C$ - событие, что выбранная вершина будет оранжевой
	\end{itemize}
	Посчитаем вероятности:
	\begin{align*}
		&{P(A) = P(B) = P(C) = 1 / 2}
		\\
		&{P(ABC) = 1 / 4}
		\\
		&{P(AB) = P(BC) = P(AC) = 1 / 4}
	\end{align*}
	Отсюда уже видно, что есть попарная независимость, но нету независимости в совокупности.
\end{example}

\section{Случайные величины}

\subsection{Определение случайной величины}

\begin{note}
	Одна из проблем, которая у нас есть (на удивление) --- это то, что мы работаем с вероятностным пространством $(\Omega, F, P)$. Более подробно, всё, что мы знаем об исходе $w$, это его вероятность. Что если мы хотим <<привязать>> числа к исходу, оценить что-то? Нам нужно выйти за рамки работы с какими-то абстракными элементами множества.
\end{note}

\begin{note}
	В текущей главе мы будем работать только с \textit{дискретным вероятностным пространством (ДВТ)}. Это значит, что $\Omega$ не более чем счётно и $F = 2^\Omega$.
\end{note}

\begin{definition}
	\textit{Случайной величиной} назовём функцию $\xi \colon \Omega \to \R$
\end{definition}

\begin{example}
	Снова рассмотрим схему Бернулли. Тогда ярким примером случайной величины может служить число удачных экспериментов:
	\[
		\xi(w) = \sum_{i = 1}^n w_i \in \N \subset \R
	\]
\end{example}

\begin{note}
	Наше определение довольно узкое. Например, под него мы не можем положить модель с геометрической вероятностью, коль скоро там $\Omega \subset \R^n$.
\end{note}

\begin{note}
	Сама по себе $\xi(w)$ не несёт смысловой нагрузки: ну вот что мы можем сказать такого про случайную величину на событии, если у нас какая-то $\xi$? Ничего осмысленного.
	
	Если приводить некорректный пример, то можно говорить о случайной величине, где исходом являются оценки по результатам сессии (например, $\Omega = \{1, \ldots, 10\}^{10}$ --- 10 оценок за какие-то 10 предметов). Какие числовые характеристики, которые можно получить через эти оценки, нас могут интересовать?
	\begin{itemize}
		\item Средний балл $\xi(w) = \frac{w_1 + \ldots + w_{10}}{10}$. Это важно для той же Абрамовской стипендии: мы хотели бы знать вероятность $P(\{w \colon \xi(w) \ge 8.6\})$
		
		\item Минимальная оценка $\eta(w) = \min\{w_i\}$. Мы бы хотели знать вероятность не попасть на пересдачу, то есть $P(\{w \colon \eta(w) > 2\})$
	\end{itemize}
	В чём проблема нашего примера? Если $F \neq 2^\Omega$, то кто обещал, что $\{w \colon \xi(w) \ge 8.6\} \in F$? Пока что мы не будем формулировать и дополнять наше определение случайной величины этим требованием, но в будущем оно появится.
\end{note}

\begin{agreement}
	Чтобы не нагромождать запись вероятности со случайными величинами, мы позволим себе 4 вещи:
	\begin{enumerate}
		\item Не писать круглые скобочки, если внутри них будут фигурные. Пример:
		\[
			P\{w \in \Omega \colon \xi(w) \ge 8.6\} := P(\{w \in \Omega \colon \xi(w) \ge 8.6\})
		\]
		
		\item Опускать целиком $w$ при описании подмножеств $\Omega$, когда работаем со случайными величинами. Пример:
		\[
			P(\xi \ge 8.6) = P\{\xi \ge 8.6\} := P\{w \in \Omega \colon \xi(w) \ge 8.6\}
		\]
		
		\item В суммах, где сверху должно писаться либо конечное число, либо бесконечность, мы будем писать снизу лишь переменную суммирования:
		\[
			\sum_k := \sum_{k = 1}^{n(\infty)}
		\]
		
		\item Если мы рассматриваем событие, которое содержит всего 1 элементарный исход $w$, то можем позволить себе не ставить фигурные скобки:
		\[
			P(w) := P(\{w\})
		\]
	\end{enumerate}
\end{agreement}

\subsection{Распределение случайной величины}

\begin{designation}
	Коль скоро наша случайная величина определена на не более чем счётном множестве, то и область значений тоже не более чем счётна. Для случайной величины $\xi \colon \Omega \to \R$ будем обозначать её как $\chi_\xi$
\end{designation}

\begin{designation}
	В силу счётности множества значений случайной величины, мы имеем право их занумеровать. Будем использовать такое сокращение для вероятности попадания в исход, при котором случайная величина $\xi \colon \Omega \to \R$ принимает значение $x_k \in \chi_\xi$:
	\[
		P_k := P\{\xi = x_k\}
	\]
\end{designation}

\begin{note}
	Естественно, имеет место следующий факт:
	\[
		\sum_k P_k = \sum_k P\{\xi = x_k\} = P\{\xi \in \chi_\xi\} = 1
	\]
\end{note}